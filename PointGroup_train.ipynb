{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"PointGroup_train.ipynb","provenance":[{"file_id":"1WKK8mvvps3SifsTOIxVw14_KvRP_2ia3","timestamp":1624531639410},{"file_id":"1gsZmCwDl-MM0SqTqBfSs1JaN_kNTeMiA","timestamp":1620632861997}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMmFlwlM/jIJKzmlw5RkmgZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Dfc-LSoL4aIV"},"source":["This is the google colab notebook for training/retraining the PointNet model for different pointgroups. There are 31 different models corresponding to the different pointgroups (pointgroup 1 does not have a model), each model is a binary predictor to indicate the presence of the pointgroup symmetries. \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BYUF-Yuq8Bov"},"source":["Please enter which pointgroup model is to be trained\n","\n","Choose from:\n","  1bar;\n","  2;\n","  m;\n","  2m;\n","  222;\n","  mm2;\n","  mmm;\n","  4;\n","  4bar;\n","  4m;\n","  422;\n","  4mm;\n","  4bar2m;\n","  4mmm;\n","  3;\n","  3bar;\n","  32;\n","  3m;\n","  3barm;\n","  6;\n","  6bar;\n","  6m;\n","  622;\n","  6mm;\n","  6barm2;\n","  6mmm;\n","  23;\n","  2m3bar;\n","  432;\n","  4bar3m;\n","  4m3bar2m;\n"]},{"cell_type":"code","metadata":{"id":"_fNCIS8rtEbY"},"source":["PG = '32'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xv5gx5gfD1mx"},"source":["# Preamble"]},{"cell_type":"markdown","metadata":{"id":"CTus__WGrwEK"},"source":["For running in Google Colab, determine the path to the folder in google drive, or clone the repository."]},{"cell_type":"code","metadata":{"id":"JJZ8HahO8Az5"},"source":["#@title Paths and Filenames\n","\n","# # Optional mount and work with google drive\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n","# path = '/content/gdrive/MyDrive/Colab Notebooks/StructurePrediction/'\n","# weights_path = path + 'Weights/'\n","# data_path = path + 'DataSets/'\n","\n","\n","# For use with Google Colab without mounting drive\n","%cd /content\n","!rm -rf crystal_structure_prediction\n","!git clone --single-branch --depth=1 https://github.com/adrianwalsh1990/crystal_structure_prediction.git\n","%cd crystal_structure_prediction\n","!unzip '/content/crystal_structure_prediction/DataSets/materialsdatabase.json.zip' -d '/content/crystal_structure_prediction/DataSets/'\n","\n","weights_path = '/content/crystal_structure_prediction/Weights/'\n","data_path = '/content/crystal_structure_prediction/DataSets/'\n","filename = 'materialsdatabase.json'\n","fname = data_path + filename \n","\n","model_name = weights_path + 'Pointgroup-' + PG\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgE9SWXO9qdG"},"source":["#@title Import libraries and  mount drive\n","!pip install trimesh\n","import pandas as pd\n","import trimesh\n","import numpy as np\n","import tensorflow as tf\n","import os\n","import glob\n","from sklearn.model_selection import train_test_split\n","from tensorflow.python.keras.activations import relu\n","from tensorflow.python.keras.backend import categorical_crossentropy\n","from tensorflow.python.keras.metrics import accuracy\n","from tensorflow.python.keras.metrics import AUC \n","from tensorflow.python.keras.metrics import FalsePositives\n","from tensorflow.python.keras.metrics import FalseNegatives\n","from tensorflow.python.keras.metrics import TruePositives\n","from tensorflow.python.keras.metrics import TrueNegatives\n","from tensorflow.python.keras.optimizer_v1 import adam\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from matplotlib import pyplot as plt\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQiY_ZBgDsZC"},"source":["# Prepare the data"]},{"cell_type":"markdown","metadata":{"id":"70RI8MzGsswL"},"source":["The atomic positions from all samples are read from the data file to a numpy array. These points are padded by repeating the first atomic site, until all inputs are of the same length."]},{"cell_type":"code","metadata":{"id":"2_4j966Z9vJL"},"source":["#@title Prepare the sites datapoints from the json file.\n","# Read in atomic positions\n","file = pd.read_json(fname)\n","x = file['structure.sites.xyz'].to_numpy()\n","\n","# Max number of atomic sites\n","num_sites = file['nsites'].to_numpy()\n","NUM_POINTS = np.amax(num_sites)\n","\n","\n","# Pad the atomic positions until all have the same number of sites\n","x_padded = np.array([xi + [xi[0]] * (NUM_POINTS - len(xi)) for xi in x])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6nGTAPLbtHdR"},"source":["The labels are all the samples are set using the space groups. The choice of PG above determines which point group is being trained. Therefore all space group labels will be converted to a 1 or 0 depending on the presence of the point group symmetry, given by the dictionary."]},{"cell_type":"code","metadata":{"id":"TBnxCQYrk3rR"},"source":["#@title Prepare the output, i.e. using the spacegroup number to indicate the presence of particular pointgroups\n","\n","y = file['spacegroup.number'].to_numpy()\n","\n","# Space group to corresponding Point Groups\n","PointGroups = {\n","    '1bar':[2] + list(range(10,16)) + list(range(47, 75)) + list(range(83,89)) +\n","           list(range(123,143)) + [147,148] + list(range(162,168)) + [175,176] +\n","           list(range(191,195)) + list(range(200,207)) + list(range(221,231)),\n","    '2':[3,4,5,10,11,12,13,14,15] + list(range(16,143)) + list(range(149, 156)) \n","        + list(range(162,174)) + list(range(175,231)),\n","    'm':list(range(6,16)) + list(range(25, 75)) + list(range(83,89)) + \n","        list(range(99,143)) + list(range(156,168)) + list(range(174,177)) + \n","        list(range(183,195)) +  list(range(200,207)) + list(range(215,231)),\n","    '2m':list(range(10,16)) + list(range(47, 75)) + list(range(83,89)) + \n","         list(range(123,143)) + list(range(162,168)) + [175, 176] + \n","         list(range(191,195)) + list(range(200,207)) + list(range(221,231)),\n","    '222':list(range(16,25)) + list(range(47, 75)) + list(range(89,99)) + \n","          list(range(111,143)) + list(range(177,183)) + list(range(191,231)),\n","    'mm2':list(range(25,75)) + list(range(99, 143)) + list(range(183,195)) + \n","          list(range(200,207)) + list(range(215,231)),\n","    'mmm':list(range(47,75)) + list(range(123, 143)) + list(range(191,195)) + \n","          list(range(200,207)) + list(range(221,231)),\n","    '4':list(range(75,81)) + list(range(83, 111)) + list(range(123,143)) + \n","        list(range(207,215)) + list(range(221,231)),\n","    '4bar':list(range(81,89)) + list(range(111, 143)) + list(range(215,231)),\n","    '4m':list(range(83,89)) + list(range(123,143)) + list(range(221,231)),\n","    '422':list(range(89,99)) + list(range(123,143)) + list(range(207,215)) + \n","          list(range(200,207)) + list(range(221,231)),\n","    '4mm':list(range(99,111)) + list(range(123,143)) + list(range(221,231)),\n","    '4bar2m':list(range(111,143)) + list(range(215,231)),\n","    '4mmm':list(range(123,143)) + list(range(221,231)),\n","    '3':list(range(143,231)),\n","    '3bar':[147,148] + list(range(162,168)) + list(range(175,177)) + \n","           list(range(191,195)) + list(range(200,207)) + list(range(221,231)),\n","    '32':list(range(149,156)) + list(range(162,168)) + list(range(177,183)) + \n","         list(range(187,195)) + list(range(207,215)) + list(range(221,231)),\n","    '3m':list(range(156,168)) + list(range(183,195)) + list(range(215,231)),\n","    '3barm':list(range(162,168)) + list(range(191,195)),\n","    '6':list(range(168,174)) + list(range(175,187)) + list(range(191,195)),\n","    '6bar':list(range(174,177)) + list(range(187,195)),\n","    '6m':[175,176] + list(range(191,195)),\n","    '622':list(range(177,183)) + list(range(191,195)),\n","    '6mm':list(range(183,187)) +  list(range(191,195)),\n","    '6barm2':list(range(187,195)),\n","    '6mmm':list(range(191,195)),\n","    '23':list(range(195,231)),\n","    '2m3bar':list(range(200,207)) + list(range(221,231)),\n","    '432':list(range(207,215)) + list(range(221,231)),\n","    '4bar3m':list(range(215,221)) + list(range(221,231)),\n","    '4m3bar2m':list(range(221,231))    \n","}\n","\n","# Covert space groups into 1/0 presence of point group\n","for i in list(set(y)):\n","    if i in PointGroups.get(PG,-1):\n","      y[y == i] = 1\n","    else:\n","      y[y==i] = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Tp097dntqQW"},"source":["Prepare the train/test datasets, which are coverted to tensors. The augmentation function is designed to jitter and shuffle the train dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"k--z7cyyD52n"},"source":["# @title Create the train/test datasets\n","\n","train_points, test_points, train_labels, test_labels = train_test_split(x_padded, y, test_size=0.1)\n","\n","def augment(points, label):\n","    # jitter points\n","    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n","    # shuffle points\n","    points = tf.random.shuffle(points)\n","    return points, label\n","\n","\n","BATCH_SIZE = 512\n","\n","train_points = tf.convert_to_tensor(train_points)\n","test_points = tf.convert_to_tensor(test_points)\n","\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_labels))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_points, test_labels))\n","\n","train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(BATCH_SIZE)\n","test_dataset = test_dataset.shuffle(len(test_points)).batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0kFIHvp92HG","executionInfo":{"status":"ok","timestamp":1635423755227,"user_tz":-120,"elapsed":404,"user":{"displayName":"Adrian Walsh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-ipmvpEzlqww2enaYr__l8pESsZ-Os141ZS95YA=s64","userId":"13651742629569272601"}},"outputId":"650c7a27-694b-4161-fa8e-952a2ee646ec"},"source":["# @title Show Histogram of Training Points\n","plt.hist(train_labels)\n","plt.show"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function matplotlib.pyplot.show>"]},"metadata":{},"execution_count":49},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"zYZpABtjEn8e"},"source":["# Create and Train the model"]},{"cell_type":"code","metadata":{"id":"l6iHNuzWpV0X"},"source":["# @title Create the model\n","\n","# Example modified from the Keras Code Example \n","# https://keras.io/examples/vision/pointnet/\n","\n","METRIC = \"TruePositives\",\"TrueNegatives\",\"FalsePositives\",\n","         \"FalseNegatives\"\n","\n","\n","def conv_bn(x, filters):\n","    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n","    x = layers.BatchNormalization(momentum=0.0)(x)\n","    return layers.Activation(\"relu\")(x)\n","\n","def dense_bn(x, filters):\n","    x = layers.Dense(filters)(x)\n","    x = layers.BatchNormalization(momentum=0.0)(x)\n","    return layers.Activation(\"relu\")(x)\n","\n","class OrthogonalRegularizer(keras.regularizers.Regularizer):\n","    def __init__(self, num_features, l2reg=0.001):\n","        self.num_features = num_features\n","        self.l2reg = l2reg\n","        self.eye = tf.eye(num_features)\n","\n","    def __call__(self, x):\n","        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n","        xxt = tf.tensordot(x, x, axes=(2, 2))\n","        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n","        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n","\n","def tnet(inputs, num_features):\n","    # Initalise bias as the indentity matrix\n","    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n","    reg = OrthogonalRegularizer(num_features)\n","\n","    x = conv_bn(inputs, 32)\n","    x = conv_bn(x, 64)\n","    x = conv_bn(x, 512)\n","    x = layers.GlobalMaxPooling1D()(x)\n","    x = dense_bn(x, 256)\n","    x = dense_bn(x, 128)\n","    x = layers.Dense(\n","        num_features * num_features,\n","        kernel_initializer=\"zeros\",\n","        bias_initializer=bias,\n","        activity_regularizer=reg,\n","    )(x)\n","    feat_T = layers.Reshape((num_features, num_features))(x)\n","    # Apply affine transformation to input features\n","    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n","\n","inputs = keras.Input(shape=(NUM_POINTS, 3))\n","\n","x = tnet(inputs, 3)\n","x = conv_bn(x, 32)\n","x = conv_bn(x, 32)\n","x = tnet(x, 32)\n","x = conv_bn(x, 32)\n","x = conv_bn(x, 64)\n","x = conv_bn(x, 512)\n","\n","x = layers.GlobalMaxPooling1D()(x)\n","\n","\n","x = dense_bn(x, 256)\n","x = layers.Dropout(0.3)(x)\n","x = dense_bn(x, 128)\n","x = layers.Dropout(0.3)(x)\n","\n","\n","outputs = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n","\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer='adam',\n","    metrics=[METRIC],\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QlipJwBzu9Pe"},"source":["Note if OOM errors occur here, consider reducing the BATCH_SIZE above, as this depends on the colab resource allocation available."]},{"cell_type":"code","metadata":{"id":"9r1sK0TB4JMw"},"source":["# @title Train new model\n","model.fit(train_dataset, epochs=100, validation_data=test_dataset)\n","\n","model.save_weights(model_name)\n","\n","results = model.evaluate(test_points, test_labels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4irellS32fCp"},"source":["The weights for the model have been saved, and can be loaded in the CrystalPrediction.ipynb to predict the presence of the point group symmetry"]}]}