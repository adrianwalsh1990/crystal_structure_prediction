{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crystal_Predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNY916Dx0xyhfygAdcpDCl+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianwalsh1990/crystal_structure_prediction/blob/main/Crystal_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfc-LSoL4aIV"
      },
      "source": [
        "This is the google colab notebook for predicting the pointgroups and Bravais lattice of a set of atomic position. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sI2zi-VFNF0Q"
      },
      "source": [
        "Set x equal to the list of atomic positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1X45WG4NEYw"
      },
      "source": [
        "x = [[\n",
        "      [0.0000000000000,\t0.00000000000000,\t0.0000000000000000],\n",
        "      [1.41159734216321632,\t4.23479202648963,\t4.23479202648963],\n",
        "      [0.00000000000000,\t2.82319468432642,\t2.82319468432642],\n",
        "      [1.41159734216321632,\t1.41159734216321632,\t1.41159734216321632],\n",
        "      [2.82319468432642,\t0.0000000000000000,\t2.82319468432642],\n",
        "      [4.23479202648963,\t4.23479202648963,\t1.41159734216321632],\n",
        "      [2.82319468432642,\t2.82319468432642,\t0.0000000000000000],\n",
        "      [4.23479202648963,\t1.41159734216321632,\t4.23479202648963]\n",
        "      ]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wALy3RkTMWaq"
      },
      "source": [
        "Please enter the crystal system:\n",
        "\n",
        "Choose from 'Triclinic', 'Monoclinic', 'Orthorhombic', 'Tetragonal', 'Trigonal', 'Hexagonal', 'Cubic'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmgq9q9kHRx3"
      },
      "source": [
        "CrySys = 'Cubic'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfpGgbD8xFt_"
      },
      "source": [
        "Run the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv5gx5gfD1mx"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn6CJBDPeBr2"
      },
      "source": [
        "For running in Google Colab, determine the path to the folder in google drive, or clone the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JostLXryeA71",
        "outputId": "93f11379-2dbe-408f-fd69-5202717108ff"
      },
      "source": [
        "#@title Paths and Filenames\n",
        "\n",
        "# # Optional mount and work with google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# path = '/content/gdrive/MyDrive/Colab Notebooks/StructurePrediction/'\n",
        "# weights_path = path + 'Weights/'\n",
        "# data_path = path + 'DataSets/'\n",
        "\n",
        "\n",
        "# For use with Google Colab without mounting drive\n",
        "%cd /content\n",
        "!rm -rf crystal_structure_prediction\n",
        "!git clone --single-branch --depth=1 https://github.com/adrianwalsh1990/crystal_structure_prediction.git\n",
        "%cd crystal_structure_prediction\n",
        "!unzip '/content/crystal_structure_prediction/DataSets/materialsdatabase.json.zip' -d '/content/crystal_structure_prediction/DataSets/'\n",
        "\n",
        "weights_path = '/content/crystal_structure_prediction/Weights/'\n",
        "data_path = '/content/crystal_structure_prediction/DataSets/'\n",
        "filename = 'materialsdatabase.json'\n",
        "fname = data_path + filename \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'crystal_structure_prediction'...\n",
            "remote: Enumerating objects: 95, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 95 (delta 38), reused 93 (delta 38), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (95/95), done.\n",
            "Checking out files: 100% (91/91), done.\n",
            "/content/crystal_structure_prediction\n",
            "Archive:  /content/crystal_structure_prediction/DataSets/materialsdatabase.json.zip\n",
            "  inflating: /content/crystal_structure_prediction/DataSets/materialsdatabase.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgE9SWXO9qdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3746b431-3b43-4cd1-96b7-5dfcadc834d8"
      },
      "source": [
        "#@title Import libraries and  mount drive\n",
        "!pip install trimesh\n",
        "import pandas as pd\n",
        "import trimesh\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.activations import relu\n",
        "from tensorflow.python.keras.backend import categorical_crossentropy\n",
        "from tensorflow.python.keras.metrics import accuracy\n",
        "from tensorflow.python.keras.metrics import AUC \n",
        "from tensorflow.python.keras.metrics import FalsePositives\n",
        "from tensorflow.python.keras.metrics import FalseNegatives\n",
        "from tensorflow.python.keras.metrics import TruePositives\n",
        "from tensorflow.python.keras.metrics import TrueNegatives\n",
        "from tensorflow.python.keras.optimizer_v1 import adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.7/dist-packages (3.9.35)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from trimesh) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trimesh) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQiY_ZBgDsZC"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_4j966Z9vJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dcc9769-d8ef-4295-ba4d-7bfab309ce0d"
      },
      "source": [
        "#@title Padding of the sites to match the input size\n",
        "file = pd.read_json(fname)\n",
        "\n",
        "# Max number of atomic sites\n",
        "num_sites = file['nsites'].to_numpy()\n",
        "NUM_POINTS = np.amax(num_sites)\n",
        "\n",
        "\n",
        "# Pad the atomic positions until all have the same number of sites\n",
        "x_padded = np.array([xi + [xi[0]] * (NUM_POINTS - len(xi)) for xi in x])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tAd7oFQuZk6"
      },
      "source": [
        "Create the PointGroup model, that matches the set of weights from the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYZpABtjEn8e"
      },
      "source": [
        "# Prediction of the point groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ePClUOHfEzw"
      },
      "source": [
        "# @title Create the model\n",
        "\n",
        "# Example modified from the Keras Code Example \n",
        "# https://keras.io/examples/vision/pointnet/\n",
        "\n",
        "METRIC = \"TruePositives\",\"TrueNegatives\",\"FalsePositives\",\"FalseNegatives\"\n",
        "\n",
        "\n",
        "def conv_bn(x, filters):\n",
        "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "def dense_bn(x, filters):\n",
        "    x = layers.Dense(filters)(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, num_features, l2reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2reg = l2reg\n",
        "        self.eye = tf.eye(num_features)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
        "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
        "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
        "\n",
        "def tnet(inputs, num_features):\n",
        "    # Initalise bias as the indentity matrix\n",
        "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
        "    reg = OrthogonalRegularizer(num_features)\n",
        "\n",
        "    x = conv_bn(inputs, 32)\n",
        "    x = conv_bn(x, 64)\n",
        "    x = conv_bn(x, 512)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = dense_bn(x, 256)\n",
        "    x = dense_bn(x, 128)\n",
        "    x = layers.Dense(\n",
        "        num_features * num_features,\n",
        "        kernel_initializer=\"zeros\",\n",
        "        bias_initializer=bias,\n",
        "        activity_regularizer=reg,\n",
        "    )(x)\n",
        "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
        "    # Apply affine transformation to input features\n",
        "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
        "\n",
        "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
        "\n",
        "x = tnet(inputs, 3)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = tnet(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 64)\n",
        "x = conv_bn(x, 512)\n",
        "\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "\n",
        "x = dense_bn(x, 256)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = dense_bn(x, 128)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "outputs = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer='adam',\n",
        "    metrics=[METRIC],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqxiG38kv_2D"
      },
      "source": [
        "Prediction of the point groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scx6AoIwOnGS",
        "outputId": "94d817d5-3e02-4eda-d07d-8452efe862bc"
      },
      "source": [
        "# Identify the necessary point groups\n",
        "PointGroups = {\n",
        "    'Triclinic': ['1bar'],\n",
        "    'Monoclinic': ['2','m','2m'],\n",
        "    'Orthorhomic':['222','mm2','mmm'],\n",
        "    'Tetragonal': ['4','4bar','4m','422','4mm','4bar2m','4mmm'],\n",
        "    'Trigonal': ['3','3bar','32','3m','3barm'],\n",
        "    'Hexagonal': ['6','6bar','6m','622','6mm','6barm2','6mmm'],\n",
        "    'Cubic':['23','2m3bar','432','4bar3m','4m3bar2m']\n",
        "}\n",
        "\n",
        "PGS = PointGroups.get(CrySys,-1)\n",
        "\n",
        "# For each point group predict whether that symmetry is present (indicated by a 1) \n",
        "# or not(indicated by a 0), by loading the correct weights for the model, and\n",
        "# making a prediction from the input points\n",
        "\n",
        "predictions = []\n",
        "for PG in PGS:\n",
        "\n",
        "  model_name = weights_path + 'Pointgroup-' + PG\n",
        "  model.load_weights(model_name)\n",
        "\n",
        "  preds = model.predict(x_padded)\n",
        "  preds[preds < 0.5] = 0\n",
        "  preds[preds >= 0.5] = 1\n",
        "\n",
        "  predictions.append(preds[0])\n",
        "  print(PG,' - ',preds[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23  -  [1.]\n",
            "2m3bar  -  [0.]\n",
            "432  -  [1.]\n",
            "4bar3m  -  [1.]\n",
            "4m3bar2m  -  [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6_MDIBrwIVY"
      },
      "source": [
        "# Prediction of the Bravais Lattices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPC8tmDVvVoA"
      },
      "source": [
        "Create the Bravais lattice model, that matches the set of weights from the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P7pzDvoZrh4"
      },
      "source": [
        "# @title Create the BRAVIS model\n",
        "\n",
        "# If the crsytal system is triclinic or hexagonal the notebook stops here as only\n",
        "# the primitive lattice is present\n",
        "if CrySys == 'Triclinic' or CrySys == 'Hexagonal':\n",
        "  !kill -9 -1\n",
        "\n",
        "\n",
        "# Depending on the crystal system certain lattices are possible\n",
        "Bravais = {    \n",
        "    'Monoclinic': ['P','C'],\n",
        "    'Orthorhomic':['P','I','F','A','C'],\n",
        "    'Tetragonal': ['P','I'],\n",
        "    'Trigonal': ['P','R'],\n",
        "    'Cubic':['P','I','F']\n",
        "}\n",
        "\n",
        "NUM_CLASSES = len(Bravais.get(CrySys,-1))\n",
        "\n",
        "def conv_bn(x, filters):\n",
        "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "def dense_bn(x, filters):\n",
        "    x = layers.Dense(filters)(x)\n",
        "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
        "    return layers.Activation(\"relu\")(x)\n",
        "\n",
        "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, num_features, l2reg=0.001):\n",
        "        self.num_features = num_features\n",
        "        self.l2reg = l2reg\n",
        "        self.eye = tf.eye(num_features)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
        "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
        "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
        "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
        "\n",
        "def tnet(inputs, num_features):\n",
        "    # Initalise bias as the indentity matrix\n",
        "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
        "    reg = OrthogonalRegularizer(num_features)\n",
        "\n",
        "    x = conv_bn(inputs, 32)\n",
        "    x = conv_bn(x, 64)\n",
        "    x = conv_bn(x, 512)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = dense_bn(x, 256)\n",
        "    x = dense_bn(x, 128)\n",
        "    x = layers.Dense(\n",
        "        num_features * num_features,\n",
        "        kernel_initializer=\"zeros\",\n",
        "        bias_initializer=bias,\n",
        "        activity_regularizer=reg,\n",
        "    )(x)\n",
        "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
        "    # Apply affine transformation to input features\n",
        "    return layers.Dot(axes=(2, 1))([inputs, feat_T])\n",
        "\n",
        "inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
        "\n",
        "x = tnet(inputs, 3)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = tnet(x, 32)\n",
        "x = conv_bn(x, 32)\n",
        "x = conv_bn(x, 64)\n",
        "x = conv_bn(x, 512)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "\n",
        "x = dense_bn(x, 256)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = dense_bn(x, 128)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
        "# model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n30YB8c_wO2n"
      },
      "source": [
        "Prediction of the Bravais Lattice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAg4AYR_Z0jM",
        "outputId": "16371485-40b9-45f9-d8b6-8fd0bce8b0a7"
      },
      "source": [
        "# load the correct Bravais lattice model\n",
        "model_name = weights_path + 'BRAVIS_' + CrySys\n",
        "model.load_weights(model_name)\n",
        "\n",
        "\n",
        "preds = model.predict(x_padded)\n",
        "\n",
        "preds[preds < 0.5] = 0\n",
        "preds[preds >= 0.5] = 1\n",
        "\n",
        "BL = Bravais.get(CrySys,-1)[np.where(preds[0] == np.amax(preds[0]))[0][0]]\n",
        "\n",
        "print('Bravais Lattice =', BL)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bravais Lattice = F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-kqPyG7wYCg"
      },
      "source": [
        "# Output of the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "6IJVeNH-wfAV",
        "outputId": "4da19679-66ba-4093-ece0-3fc65ffde1f5"
      },
      "source": [
        "# @title Output:\n",
        "print('Bravais Lattice =', BL)\n",
        "\n",
        "for i in range(len(PGS)):\n",
        "  print(PGS[i],'\\t',predictions[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bravais Lattice = F\n",
            "23 \t [1.]\n",
            "2m3bar \t [0.]\n",
            "432 \t [1.]\n",
            "4bar3m \t [1.]\n",
            "4m3bar2m \t [1.]\n"
          ]
        }
      ]
    }
  ]
}